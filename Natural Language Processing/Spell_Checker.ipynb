{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "Xey-8crmJ_xK"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1.Finding unique words"
      ],
      "metadata": {
        "id": "HoUA10LoKwYJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "X_qNHfTlyM7P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b82fe8c4-fe4e-4f1b-8edd-1c652d87ebbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "184982\n",
            "12979\n"
          ]
        }
      ],
      "source": [
        "with open('big.txt','r') as fd:\n",
        "  lines = fd.readlines()\n",
        "  words = []\n",
        "  for line in lines:\n",
        "    words += re.findall('\\w+',line.lower())\n",
        "print(len(words))\n",
        "vocab = set(words)\n",
        "print(len(vocab))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.Finding probability distribution"
      ],
      "metadata": {
        "id": "E1pE4zZCK4DY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_probability = {}\n",
        "for word in tqdm(vocab):\n",
        "  word_probability[word] = float(words.count(word)/len(words))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OY-XepmiJqny",
        "outputId": "727ad419-0136-4cdb-c3a6-59c364e721bd"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12979/12979 [00:58<00:00, 220.47it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(word_probability)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5Vbg2CpL01A",
        "outputId": "bb699ad1-e7b4-4295-c291-c1cdc1e0b317"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12979"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Text preprocessing\n",
        "#### 3.1) Splitting and Deleting\n",
        "\"loive\" -> \"love\""
      ],
      "metadata": {
        "id": "mPNHG4R9Mlta"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split(word):\n",
        "  parts = []\n",
        "  for i in range(len(word)+1):\n",
        "    parts += [(word[:i], word[i:])]\n",
        "  return parts\n",
        "print(split('anurag'))\n",
        "\n",
        "def delete(word):\n",
        "  output = []\n",
        "  for l,r in split(word):\n",
        "    output.append(l+r[1:])\n",
        "  return output\n",
        "delete('heallo')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Izh97VZ8NoDg",
        "outputId": "8fba0902-a787-4b41-b131-88edb7d95b42"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('', 'anurag'), ('a', 'nurag'), ('an', 'urag'), ('anu', 'rag'), ('anur', 'ag'), ('anura', 'g'), ('anurag', '')]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['eallo', 'hallo', 'hello', 'healo', 'healo', 'heall', 'heallo']"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.2) Swap\n",
        "'lvoe' -> 'love'"
      ],
      "metadata": {
        "id": "J4SsedsXNKdi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def swap(word):\n",
        "  output = []\n",
        "  for l,r in split(word):\n",
        "    if(len(r)>1):\n",
        "      output.append(l + r[1]+r[0] + r[2:])\n",
        "  return output\n",
        "swap('lvoe')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvQlIuk9Nobg",
        "outputId": "e9f62b31-b4f4-425e-e952-8a04fce630a0"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['vloe', 'love', 'lveo']"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.3) Replace\n",
        "'lave' -> 'love'"
      ],
      "metadata": {
        "id": "jiEV4R_UNTHG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def replace(word):\n",
        "  output = []\n",
        "  for l,r in split(word):\n",
        "    for i in range(0,26):\n",
        "      output.append(l+chr(97+i)+r[1:])\n",
        "  return output\n",
        "len(replace('lave'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XW-HtKw3NozY",
        "outputId": "5a69bd1b-c349-48d3-8d67-6002fbc2284e"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "130"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.4) Insert\n",
        "'lve' -> 'love'"
      ],
      "metadata": {
        "id": "Ya8NiNnsNYaN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def insert(word):\n",
        "    output = []\n",
        "    for l,r in split(word):\n",
        "        for i in range(0,26):\n",
        "            output.append(l+chr(97+i)+r)\n",
        "    return output\n",
        "insert('lve')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UbI0ei66MmCv",
        "outputId": "78bb39ba-8158-4a2c-d842-47ed3897b7ac"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['alve',\n",
              " 'blve',\n",
              " 'clve',\n",
              " 'dlve',\n",
              " 'elve',\n",
              " 'flve',\n",
              " 'glve',\n",
              " 'hlve',\n",
              " 'ilve',\n",
              " 'jlve',\n",
              " 'klve',\n",
              " 'llve',\n",
              " 'mlve',\n",
              " 'nlve',\n",
              " 'olve',\n",
              " 'plve',\n",
              " 'qlve',\n",
              " 'rlve',\n",
              " 'slve',\n",
              " 'tlve',\n",
              " 'ulve',\n",
              " 'vlve',\n",
              " 'wlve',\n",
              " 'xlve',\n",
              " 'ylve',\n",
              " 'zlve',\n",
              " 'lave',\n",
              " 'lbve',\n",
              " 'lcve',\n",
              " 'ldve',\n",
              " 'leve',\n",
              " 'lfve',\n",
              " 'lgve',\n",
              " 'lhve',\n",
              " 'live',\n",
              " 'ljve',\n",
              " 'lkve',\n",
              " 'llve',\n",
              " 'lmve',\n",
              " 'lnve',\n",
              " 'love',\n",
              " 'lpve',\n",
              " 'lqve',\n",
              " 'lrve',\n",
              " 'lsve',\n",
              " 'ltve',\n",
              " 'luve',\n",
              " 'lvve',\n",
              " 'lwve',\n",
              " 'lxve',\n",
              " 'lyve',\n",
              " 'lzve',\n",
              " 'lvae',\n",
              " 'lvbe',\n",
              " 'lvce',\n",
              " 'lvde',\n",
              " 'lvee',\n",
              " 'lvfe',\n",
              " 'lvge',\n",
              " 'lvhe',\n",
              " 'lvie',\n",
              " 'lvje',\n",
              " 'lvke',\n",
              " 'lvle',\n",
              " 'lvme',\n",
              " 'lvne',\n",
              " 'lvoe',\n",
              " 'lvpe',\n",
              " 'lvqe',\n",
              " 'lvre',\n",
              " 'lvse',\n",
              " 'lvte',\n",
              " 'lvue',\n",
              " 'lvve',\n",
              " 'lvwe',\n",
              " 'lvxe',\n",
              " 'lvye',\n",
              " 'lvze',\n",
              " 'lvea',\n",
              " 'lveb',\n",
              " 'lvec',\n",
              " 'lved',\n",
              " 'lvee',\n",
              " 'lvef',\n",
              " 'lveg',\n",
              " 'lveh',\n",
              " 'lvei',\n",
              " 'lvej',\n",
              " 'lvek',\n",
              " 'lvel',\n",
              " 'lvem',\n",
              " 'lven',\n",
              " 'lveo',\n",
              " 'lvep',\n",
              " 'lveq',\n",
              " 'lver',\n",
              " 'lves',\n",
              " 'lvet',\n",
              " 'lveu',\n",
              " 'lvev',\n",
              " 'lvew',\n",
              " 'lvex',\n",
              " 'lvey',\n",
              " 'lvez']"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Finding the prediction\n",
        "#### 4.1) Combining possible words"
      ],
      "metadata": {
        "id": "fVzSmQbVVxWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def edit(word):\n",
        "  return list(set(insert(word)+delete(word)+swap(word)+replace(word)))\n",
        "len(edit('loave'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9kfMcveV5RS",
        "outputId": "530656f7-59c0-4f19-c6f5-f3d72be25de9"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "286"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.2) Predicting the word"
      ],
      "metadata": {
        "id": "eaJYIPAt6uon"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def spell_check_edit_1(word, word_probability, count = 5):\n",
        "  output = []\n",
        "\n",
        "  suggested_words = edit(word)\n",
        "\n",
        "  for wrd in suggested_words:\n",
        "    if wrd in word_probability.keys():\n",
        "      output.append([wrd,word_probability[wrd]])\n",
        "\n",
        "  return list(pd.DataFrame(output,columns = ['word','prob']).sort_values(by = 'prob', ascending = False).head(count)['word'].values)"
      ],
      "metadata": {
        "id": "lZUUVcfA5U2i"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spell_check_edit_1('lover',word_probability,10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRasW97G5ZpF",
        "outputId": "426be2d4-47e3-4013-fa89-b53a4000ca19"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['over',\n",
              " 'love',\n",
              " 'lower',\n",
              " 'lover',\n",
              " 'loved',\n",
              " 'cover',\n",
              " 'loves',\n",
              " 'rover',\n",
              " 'hover',\n",
              " 'liver']"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Finding the prediction (Level - 2)\n",
        "#### 5.1) Combining Possible Words"
      ],
      "metadata": {
        "id": "hgwNc49-9H3a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def spell_check_edit_2(word,word_probability,count=5):\n",
        "  output = []\n",
        "  suggested_words = edit(word) # first level edit\n",
        "  for e1 in edit(word):\n",
        "    suggested_words += edit(e1) # second level edit\n",
        "  suggested_words = set(suggested_words)\n",
        "  for wrd in suggested_words:\n",
        "    if wrd in word_probability.keys():\n",
        "      output.append([wrd,word_probability[wrd]])\n",
        "  return list(pd.DataFrame(output,columns = ['word','prob']).sort_values(by = 'prob', ascending = False).head(count)['word'].values)"
      ],
      "metadata": {
        "id": "okW7xE-e9S9B"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(spell_check_edit_1('fameli',word_probability))\n",
        "spell_check_edit_2('fameli',word_probability)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrHYEUfs_IVh",
        "outputId": "5c03f95f-fc47-4b69-9d64-a4872569facc"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['family', 'namely', 'fame', 'lamely']"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    }
  ]
}